{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0231e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0577d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['bye', 'hello', 'you']\n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "\n",
    "sequences, labels = [], []\n",
    "\n",
    "img_size = 224\n",
    "# DATA_PATH = os.path.join('Action_Frame', action)\n",
    "data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    DATA_PATH = os.path.join('Action_Frame', action)\n",
    "    # print(DATA_PATH)\n",
    "    # print(os.listdir(DATA_PATH))\n",
    "    class_num = actions.index(action)\n",
    "    # print(class_num)\n",
    "    for img in os.listdir(DATA_PATH):\n",
    "        try:\n",
    "            img_arr = cv2.imread(os.path.join(DATA_PATH, img))[..., ::-1]  # convert BGR to RGB format\n",
    "            resized_arr = cv2.resize(img_arr, (img_size, img_size))  # Reshaping images to preferred size\n",
    "            data.append([resized_arr, class_num])\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ac898",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for action in actions:\n",
    "    DATA_PATH = os.path.join('Actions_test', action)\n",
    "    # print(DATA_PATH)\n",
    "    # print(os.listdir(DATA_PATH))\n",
    "    class_num = actions.index(action)\n",
    "    # print(class_num)\n",
    "    for img in os.listdir(DATA_PATH):\n",
    "        try:\n",
    "            img_arr = cv2.imread(os.path.join(DATA_PATH, img))[..., ::-1]  # convert BGR to RGB format\n",
    "            resized_arr = cv2.resize(img_arr, (img_size, img_size))  # Reshaping images to preferred size\n",
    "            val.append([resized_arr, class_num])\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faafea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for feature, label in data:\n",
    "  x_train.append(feature)\n",
    "  y_train.append(label)\n",
    "\n",
    "for feature, label in val:\n",
    "  x_val.append(feature)\n",
    "  y_val.append(label)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143b651",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs = 100 ,  verbose=1, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed681038",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(100)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f210d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_val)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "print(classification_report(y_val, predictions, target_names = ['bye (Class 0)','hello (Class 1)','you (Class 2)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab160b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('act_ion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "# from PIL import Image, ImageGrab\n",
    "# from io import BytesIO\n",
    "# i = ImageGrab.grab()\n",
    "# i.resize(480, 480)\n",
    "# output = BytesIO()\n",
    "# i.save(output, format=\"JPEG\")\n",
    "# output.flush()\n",
    "# output.seek(0)\n",
    "# print(isinstance(Image.open(output),Image.Image))\n",
    "\n",
    "# This portion is part of my test code\n",
    "byteImgIO = io.BytesIO()\n",
    "byteImg = Image.open(\"/home/meeni/PycharmProjects/Facedetaction/Action_Frame/bye/Frame21.jpg\")\n",
    "byteImg.save(byteImgIO, \"JPEG\")\n",
    "byteImgIO.seek(0)\n",
    "byteImg = byteImgIO.read()\n",
    "\n",
    "\n",
    "# Non test code\n",
    "dataBytesIO = io.BytesIO(byteImg)\n",
    "img = Image.open(dataBytesIO)\n",
    "\n",
    "# for name, file_info in uploader.value.items():\n",
    "#     img = Image.open(io.BytesIO(file_info['content']))\n",
    "# print(img)\n",
    "\n",
    "# from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    " \n",
    "#   # predicting images\n",
    "path = \"/home/meeni/PycharmProjects/Facedetaction/Action_Frame/bye/Frame21.jpg\"\n",
    "img = image.load_img(path, target_size=(480, 480))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "image_tensor = np.vstack([x])\n",
    "classes = model.predict(image_tensor)\n",
    "print(classes)\n",
    "print(classes[0])\n",
    "if classes[0]>0.5:\n",
    "    print(\"is a human\")\n",
    "else:\n",
    "    print(\"is a horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab41ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
